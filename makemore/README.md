In this lecture a bigram (one character predicts the next one)
character-level language model will be implemented. The focus is set on 
#### (1) introducing torch.Tensor and its subtleties and use in efficiently evaluating neural networks as well as 
#### (2) the overall framework of language modeling that includes model training, smpling and the evaluation of a loss.

### finish the exercise in the end of the notebook
##### 1- Ecncluding doing Tri_gram
##### 2- Splitting the data and try different loss function 
