{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moY8IOKlrm9b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the names.txt file from github\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmmM8POvrtco",
        "outputId": "6d33ddc5-ac58-43b4-9129-487affd36be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-08 08:41:01--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‘names.txt’\n",
            "\n",
            "\rnames.txt             0%[                    ]       0  --.-KB/s               \rnames.txt           100%[===================>] 222.80K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-01-08 08:41:01 (13.3 MB/s) - ‘names.txt’ saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # read in all the words\n",
        "words = open('names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KZE_EtNru_P",
        "outputId": "369fe917-bcda-4a85-bd50-7ddaea2634b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXRALF1xr2od",
        "outputId": "a45bb015-2a6d-4b64-e6ac-c5e6186bc908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 8 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):  \n",
        "  X, Y = [], []\n",
        "  \n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY9RYt-or3pu",
        "outputId": "0b3198bc-617e-49b5-9e1a-a3c26320626d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 8]) torch.Size([182625])\n",
            "torch.Size([22655, 8]) torch.Size([22655])\n",
            "torch.Size([22866, 8]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x,y in zip(Xtr[:20], Ytr[:20]):\n",
        "  print(''.join(itos[ix.item()] for ix in x), '-->', itos[y.item()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd8ScoCVcmd4",
        "outputId": "208393b8-9402-4383-f363-c6082eae7dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "........ --> y\n",
            ".......y --> u\n",
            "......yu --> h\n",
            ".....yuh --> e\n",
            "....yuhe --> n\n",
            "...yuhen --> g\n",
            "..yuheng --> .\n",
            "........ --> d\n",
            ".......d --> i\n",
            "......di --> o\n",
            ".....dio --> n\n",
            "....dion --> d\n",
            "...diond --> r\n",
            "..diondr --> e\n",
            ".diondre --> .\n",
            "........ --> x\n",
            ".......x --> a\n",
            "......xa --> v\n",
            ".....xav --> i\n",
            "....xavi --> e\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's train a deeper network\n",
        "# The classes we create here are the same API as nn.Module in PyTorch\n",
        "\n",
        "class Linear:\n",
        "  \"\"\"\n",
        "      Class work as a linear layer\n",
        "  \"\"\"\n",
        "  def __init__(self, fan_in, fan_out, bias=True): \n",
        "    \"\"\"\n",
        "        Object Initialization for the weight and bias.\n",
        "        Input:\n",
        "            - fan_in: nomber of inputs\n",
        "            - fan_out: number of output\n",
        "            - bias: weather you want bias or not.\n",
        "        Output:\n",
        "             - Tensors for bias and weight\n",
        "\n",
        "      \"\"\"\n",
        "#when the bias will be None?\n",
        "    self.weight = torch.randn((fan_in, fan_out), generator=g) / fan_in**0.5\n",
        "    self.bias = torch.zeros(fan_out) if bias else None\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    \"\"\"\n",
        "        Calculate creates Linear mathimatical.\n",
        "        Input:\n",
        "            - x: input data\n",
        "        Output:\n",
        "             - x @ weight + bias\n",
        "\n",
        "    \"\"\"\n",
        "    self.out = x @ self.weight\n",
        "    if self.bias is not None:\n",
        "      self.out += self.bias\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    \"\"\"\n",
        "        Creates list for weights and bias.\n",
        "        Output:\n",
        "             - list for bias and weight\n",
        "\n",
        "    \"\"\"\n",
        "    return [self.weight] + ([] if self.bias is None else [self.bias])\n",
        "\n",
        "\n",
        "class BatchNorm1d:\n",
        "  \"\"\"\n",
        "      Applies Batch noralization over the data\n",
        "  \"\"\"\n",
        "  \n",
        "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
        "    \"\"\"\n",
        "      Object Initialization.\n",
        "      Input:\n",
        "          - dim: dim number\n",
        "          - eps: used to avoid division by zero\n",
        "          - momentum: used to keep tracking of the runing mean and std.\n",
        "          - gamma and beta: parameters for BatchNorm1d.\n",
        "          - running_mean, running_var: buffers(not parameter of this layer) \n",
        "            trained using exponential moving avarage(not part of backpropagation)\n",
        "    \"\"\"\n",
        "    self.eps = eps#saving eps\n",
        "    self.momentum = momentum\n",
        "    self.training = True\n",
        "    # parameters (trained with backprop)\n",
        "    self.gamma = torch.ones(dim)\n",
        "    self.beta = torch.zeros(dim)\n",
        "    # buffers (trained with a running 'momentum update')\n",
        "    self.running_mean = torch.zeros(dim)\n",
        "    self.running_var = torch.ones(dim)\n",
        "  \n",
        "  def __call__(self, x):\n",
        "    \"\"\"\n",
        "      Object Initialization.\n",
        "      Input:\n",
        "          - x: input data\n",
        "      Output:\n",
        "            - the data after normalization\n",
        "\n",
        "    \"\"\"\n",
        "    # calculate the forward pass\n",
        "    if self.training:\n",
        "      if x.ndim == 2:\n",
        "        dim = 0\n",
        "      elif x.ndim == 3:\n",
        "        dim  = (0, 1)\n",
        "      #while training we will use the mean and variance estimated from current batch\n",
        "      xmean = x.mean(dim, keepdim=True) # batch mean\n",
        "      xvar = x.var(dim, keepdim=True) # batch variance\n",
        "    else:\n",
        "      #while evaluation we will use the running_mean and running_var estimated from current batch\n",
        "      xmean = self.running_mean\n",
        "      xvar = self.running_var\n",
        "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n",
        "    self.out = self.gamma * xhat + self.beta\n",
        "    # update the buffers\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "        #while training we will ubdate running_var, running_mean, but while testing will not be updated.\n",
        "        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n",
        "        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.gamma, self.beta]\n",
        "\n",
        "class Tanh:\n",
        "  \"\"\"\n",
        "      Calculate the tanh\n",
        "  \"\"\"\n",
        "  def __call__(self, x):\n",
        "    self.out = torch.tanh(x)\n",
        "    return self.out\n",
        "  def parameters(self):\n",
        "    return []#have no parameter\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "class Embedding:\n",
        "\n",
        "  def __init__(self, num_embeddings, embedding_dim):\n",
        "    self.weight = torch.randn((num_embeddings, embedding_dim))\n",
        "    \n",
        "  def __call__(self, IX):\n",
        "    self.out = self.weight[IX]\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.weight]\n",
        "#-----------------------------------------------------------------------------\n",
        "class FlattenConsecutive:\n",
        "# n: number of consecutive elements  we wnat to concatenete\n",
        "  def __init__(self, n):\n",
        "    self.n = n\n",
        "\n",
        "  def __call__(self, x):\n",
        "    B, T, C = x.shape\n",
        "    x = x.view(B, T//self.n, C*self.n)\n",
        "    if x.shape[1] == 1:\n",
        "      x = x.squeeze(1)\n",
        "    self.out = x\n",
        "    return self.out\n",
        "  def parameters(self):\n",
        "    return []\n",
        "#-----------------------------------------------------------------------------\n",
        "class Sequential:\n",
        "\n",
        "  def __init__(self, layers):\n",
        "    self.layers = layers\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for layer in self.layers:\n",
        "      x = layer(x)\n",
        "    self.out = x\n",
        "    return self.out\n",
        "  def parameters(self):\n",
        "    return [p for layer in self.layers for p in layer.parameters()]"
      ],
      "metadata": {
        "id": "vgNBcKs8sLX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 24 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 128 # the number of neurons in the hidden layer of the MLP\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "\n",
        "#C = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "#stack the layers up as a list as multi_layer perceptron\n",
        "#----------------with batchnormalization-----------------------\n",
        "model = Sequential([\n",
        "  Embedding(vocab_size, n_embd),\n",
        "  FlattenConsecutive(2),Linear(n_embd * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  FlattenConsecutive(2),Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  FlattenConsecutive(2),Linear(n_hidden * 2, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n",
        "  Linear(n_hidden, vocab_size)\n",
        "])\n",
        "with torch.no_grad():\n",
        "  # last layer: make less confident of the softmax\n",
        "  model.layers[-1].weight *= 0.1\n",
        "\n",
        "\n",
        "parameters = model.parameters()\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xfBKEEArn_L",
        "outputId": "7c16d8f2-eed1-4817-e33f-3bbb02aa0662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = [] \n",
        "\n",
        "for i in range(max_steps):\n",
        "  \n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "  \n",
        "  # forward pass\n",
        "  logits = model(Xb)\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "  \n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "  \n",
        "  # update\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c21ja-rfsM-a",
        "outputId": "c44f13e2-f989-41e9-ca71-bb691e67ffbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.2973\n",
            "  10000/ 200000: 1.7464\n",
            "  20000/ 200000: 1.7888\n",
            "  30000/ 200000: 1.9589\n",
            "  40000/ 200000: 2.1329\n",
            "  50000/ 200000: 1.9487\n",
            "  60000/ 200000: 2.1313\n",
            "  70000/ 200000: 1.6079\n",
            "  80000/ 200000: 1.8670\n",
            "  90000/ 200000: 2.3589\n",
            " 100000/ 200000: 2.1312\n",
            " 110000/ 200000: 1.4416\n",
            " 120000/ 200000: 1.8272\n",
            " 130000/ 200000: 2.2844\n",
            " 140000/ 200000: 1.7971\n",
            " 150000/ 200000: 2.0377\n",
            " 160000/ 200000: 1.7928\n",
            " 170000/ 200000: 1.8039\n",
            " 180000/ 200000: 2.3848\n",
            " 190000/ 200000: 1.4510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(torch.tensor(lossi).view(-1, 1000).mean(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "H7FB9sYInlCE",
        "outputId": "ecb36580-de64-4ee5-9c25-bd2473fb1910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2c37720100>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehknU7xtbHwz"
      },
      "outputs": [],
      "source": [
        "# put layers into eval mode (needed for batchnorm especially)\n",
        "for layer in model.layers:\n",
        "  layer.training = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5W1wFpKubHwz",
        "outputId": "877e1780-d018-46be-aa60-bf4b4c320744",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 1.7637085914611816\n",
            "val 1.988756775856018\n"
          ]
        }
      ],
      "source": [
        "# evaluate the loss\n",
        "@torch.no_grad() # this decorator disables gradient tracking inside pytorch\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  logits = model(x)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### performance log\n",
        "\n",
        "- original (3 character context + 200 hidden neurons, 12K params): train 2.058, val 2.105\n",
        "- context: 3 -> 8 (22K params): train 1.918, val 2.027\n",
        "- flat -> hierarchical (22K params): train 1.94, val 2.030\n",
        "- fix bug in batchnorm: train 1.909, val 2.022\n",
        "- scale up the network: n_embd 24, n_hidden 128 (76K params): train 1.763, val 1.988\n"
      ],
      "metadata": {
        "id": "ECE6xLvshZM0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSE5ZEgebHw0",
        "outputId": "3610bfc1-6b3c-4863-f221-65fbf82e44b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bless.\n",
            "fatif.\n",
            "brissam.\n",
            "kyrabel.\n",
            "prish.\n",
            "faw.\n",
            "narius.\n",
            "jezika.\n",
            "silveris.\n",
            "sajen.\n",
            "ana.\n",
            "auston.\n",
            "ronita.\n",
            "salima.\n",
            "giare.\n",
            "diana.\n",
            "robbet.\n",
            "jasmeno.\n",
            "kaysen.\n",
            "ayla.\n"
          ]
        }
      ],
      "source": [
        "# sample from the model\n",
        "for _ in range(20):\n",
        "    \n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass the neural net\n",
        "      logits = model(torch.tensor([context]))\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1).item()\n",
        "      # shift the context window and track the samples\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      # if we sample the special '.' token, break\n",
        "      if ix == 0:\n",
        "        break\n",
        "    \n",
        "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debugging what happend inside the BatchNorlalization"
      ],
      "metadata": {
        "id": "_jbd1H_3aQLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = torch.randn(32, 4, 68)\n",
        "emean = e.mean((0, 1), keepdim = True) #1, 4, 68\n",
        "evar = e.var((0, 1), keepdim = True) #1, 4, 68\n",
        "ehat = (e - emean)/torch.sqrt(evar + 1e-5) #32, 4, 68\n",
        "ehat.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8nXU7sqaUhM",
        "outputId": "e7468e27-cb5e-412c-8edc-0747770400b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 4, 68])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[3].running_mean.shape #we should have only 68 but now batchnorm working parallel on 4 of\n",
        "#68 channels so we wnat to find the mean and var for tuple of (32, 4) so\n",
        "# we will change e.mean(0, keepdim = True) to e.mean((0, 1), keepdim = True) so the out \n",
        "#  #1, 1, 68\n",
        "# the running_mean will be the same only the dim = 4 is an spurious dim\n",
        "# so we only maintaining the mean and var for 68 channels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgmXxWINaUi4",
        "outputId": "f94b707b-7e64-49b0-ffc0-f0133252b67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 68])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p245P1rtaUmn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debugging what happend inside the model"
      ],
      "metadata": {
        "id": "XhO1oxu1aIZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(0, Xtr.shape[0], (4, ))\n",
        "Xb, Yb  = Xtr[ix], Ytr[ix]\n",
        "logits = model(Xb)\n",
        "print(Xb.shape)\n",
        "Xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxJf7JTr_HkW",
        "outputId": "136f7a49-cbff-4cc3-ba3d-8c4e22bacd9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 8])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0,  0,  0,  0, 10],\n",
              "        [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 0,  0, 12,  5,  5, 12,  5, 14],\n",
              "        [ 0,  0,  0,  0,  0,  0,  3,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in model.layers:\n",
        "  print(layer.__class__.__name__, ':', tuple(layer.out.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70i_tMLvQYQZ",
        "outputId": "c817632c-b23b-4096-9506-cedf72edc29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding : (4, 8, 10)\n",
            "FlattenConsecutive : (4, 4, 20)\n",
            "Linear : (4, 4, 200)\n",
            "BatchNorm1d : (4, 4, 200)\n",
            "Tanh : (4, 4, 200)\n",
            "FlattenConsecutive : (4, 2, 400)\n",
            "Linear : (4, 2, 200)\n",
            "BatchNorm1d : (4, 2, 200)\n",
            "Tanh : (4, 2, 200)\n",
            "FlattenConsecutive : (4, 400)\n",
            "Linear : (4, 200)\n",
            "BatchNorm1d : (4, 200)\n",
            "Tanh : (4, 200)\n",
            "Linear : (4, 27)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[0].out.shape #output of embedding layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEJmHhEF_HnN",
        "outputId": "1cb193ad-71a0-40dc-e211-ca17d0ab99ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[1].out.shape #output of flatten layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KoWxFSTBi3N",
        "outputId": "0e32c786-48bc-467b-bd87-72474fbef993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 80])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[2].out.shape #output of linear layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHWDcLdFBi9m",
        "outputId": "ac609ac8-9b54-42b4-c610-bbeac50e565a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(torch.randn(4,80) @ torch.randn(80,200) + torch.randn(200)).shape #how linear layer works"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBvqUicbFboS",
        "outputId": "7b4c552d-1259-40f3-840d-cca6618bcd1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we have 8 numbers and we wnat to fuse each two numbers \n",
        "# so what we have done is we create 4 groups in each (4, 20) \n",
        "# we should change the flatten layer to give us (4, 4, 20)\n",
        "(torch.randn(4, 4, 20) @ torch.randn(20,200) + torch.randn(200)).shape #how linear layer works"
      ],
      "metadata": {
        "id": "6WAKfIVuHB_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (1 2) (3 4) (5 6) (7 8) "
      ],
      "metadata": {
        "id": "KEevezz8BplY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}